# -*- coding: utf-8 -*-
"""git-mod hw3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iAs8Tp9_EHaeHauSpRwgg9VViFqoD-C1

Here, we will implement [Tao's vanilla model](http://www.drhongtao.com/courses/dahlf) using `sklearn`, for which we need to explicitly create the $284$ predictor variables. The results should be the same as in the lecture notes (where `statsmodels` is used).

First, we create a function to calculate the MAPE, and import the data:
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
def mape(a, f):
    return np.mean(np.abs((a - f) / a))
df = pd.read_csv('bse_clean.csv', parse_dates=['Date'])
df['Trend'] = df.index
df['Day'] = df['Date'].dt.dayofweek
df

"""The task is to create the `X` matrix, with $284$ columns and $51192$ rows. The $284$ columns (excluding the `Intercept` column) should exactly match the coefficients shown below the `results.summary()` in the lecture notes."""

# seperating T and Trend columns to avoid transpose of X matrix
t1=df.drop(['Date','Hour','Load','Month','Trend','Day'],axis=1)
trend1=df.drop(['Date','Hour','Load','Month','T','Day'],axis=1)

# Dropping columns based on load formula from Tao Vanilla's model--> Load ~ Trend + C(Day):C(Hour) + (C(Month) + C(Hour)) * (T + I(T ** 2) + I(T ** 3))
# Month: 11 dummy variables and Hour:23 dummy variables -> 1 is dropped in each case, 
# For Day*Hour case: 24*6 dummy variables because only 1 variable in Day is dropped and none in Month
# Similarly, for Month*T^2 :11 variables, for Month*T^3 :11 variables, Hour*T :23 variables, Hour * T^2 :23 variables, Hour*T^3 :23 variables
# T, Tsquare, Tcube :1 variable each since these are predictor variables 

df_new = df.drop(['Date','Load'],axis=1)

dummy_hour = pd.get_dummies(df_new.Hour)
hour_new = dummy_hour.drop([1],axis=1)

dummy_month = pd.get_dummies(df_new.Month)
month_new = dummy_month.drop([1],axis=1)

dummy_day = pd.get_dummies(df_new.Day)
day_new = dummy_day.drop([0],axis=1)

# forming each of the terms individually in the load formula and joining them together to form the required X matrix

day_hour=pd.concat([day_new[i]*dummy_hour[j] for i in day_new for j in dummy_hour],axis=1)

hour_t=pd.concat([hour_new[i]*t1[j] for i in hour_new for j in t1],axis=1)
hour_t2=pd.concat([hour_t[i]*t1[j] for i in hour_t for j in t1],axis=1)
hour_t3=pd.concat([hour_t2[i]*t1[j] for i in hour_t2 for j in t1],axis=1)

month_t=pd.concat([month_new[i]*t1[j] for i in month_new for j in t1],axis=1)
month_t2=pd.concat([month_t[i]*t1[j] for i in month_t for j in t1],axis=1)
month_t3=pd.concat([month_t2[i]*t1[j] for i in month_t2 for j in t1],axis=1)

t1Square=pd.concat([t1[i]*t1[j] for i in t1 for j in t1],axis=1)
t1Cube=pd.concat([t1Square[i]*t1[j] for i in t1Square for j in t1],axis=1)

X=pd.concat([ month_new, hour_new, day_hour, trend1, t1, month_t, hour_t, t1Square, month_t2, hour_t2, t1Cube, month_t3, hour_t3 ], axis=1)
print('X-matrix:'+str(X.shape))
X=X.values
print(X)
print("No. of rows:"+str(len(X)))
print("No of Columns:"+str(len(X[0])))

"""Verifying intercept and MAPE as in the lecture notes."""

train = (df['Date'].dt.year >= 2004) & (df['Date'].dt.year <= 2006)
test = (df['Date'].dt.year >= 2007) & (df['Date'].dt.year <= 2008)
X_train = X[train]
y_train = df['Load'][train]
X_test = X[test]
y_test = df['Load'][test]
reg = LinearRegression().fit(X_train, y_train)
reg.intercept_, mape(y_test, reg.predict(X_test))

# checking coefficients of intercept also to match that in the lecture
reg.coef_

